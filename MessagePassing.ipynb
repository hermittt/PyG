{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN\n",
    "$$\n",
    "X' = D^{0.5}AD^{-0.5}XW\n",
    "$$\n",
    "node-wise:\n",
    "$$\n",
    "x' = \\sum_j{[e_{ij}/sqrt(d_i*d_j)]*(x_j·W)}\n",
    "$$\n",
    "## edge_weight写法参考\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html?highlight=propagate#the-messagepassing-base-class\n",
    "- +edge_weight\n",
    "- https://github.com/zwt233/AIR/blob/c83b27a17f6b4fa37b70f5a1492dcdb4636a970a/src/OGB/layer.py#L138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree, add_self_loops, add_remaining_self_loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`propagate()`方法 internally(内部) calls `message()`, `aggregate()` and `update()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5). #*batch node_dim默认=-2,可以适应有/无batch情况\n",
    "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight = None):#* 添加可修改权重edge_weight\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_weight, num_nodes=x.size(0)) #*edge_weight\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(-2), dtype=x.dtype) #*batch\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        norm_edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col] #*edge_weight\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        if edge_weight == None:\n",
    "            out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        else:\n",
    "            out = self.propagate(edge_index, x=x, norm=norm_edge_weight)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "x = torch.rand([3,3,2]) # B,N,C\n",
    "edge_index = torch.tensor( [[0,1],\n",
    "                            [1,2]])\n",
    "edge_weight = torch.tensor( [0.5,0.5])\n",
    "model=GCNConv(x.shape[-1],1)\n",
    "model(x,edge_index,edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试edge_weight\n",
    "```\n",
    ">>>norm\n",
    "tensor([0.7071, 0.5000, 1.0000, 0.5000, 0.5000])\n",
    ">>>norm_edge_weight\n",
    "tensor([0.3536, 0.2500, 1.0000, 0.5000, 0.5000])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self_loops\n",
    "> edge_index = torch.tensor( [[0,1,2],\n",
    "                            [1,2,2]])\n",
    "\n",
    "```\n",
    "# add_self_loops添加自环会重复\n",
    "add_self_loops(edge_index, num_nodes=x.shape[0])[0]\n",
    "\n",
    "tensor([[0, 1, 2, 0, 1, 2],\n",
    "        [1, 2, 2, 0, 1, 2]])\n",
    "\n",
    "# add_remaining_self_loops 则能排除重复\n",
    "add_remaining_self_loops(edge_index, num_nodes=x.shape[0])[0]\n",
    "\n",
    "tensor([[0, 1, 0, 1, 2],\n",
    "        [1, 2, 0, 1, 2]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT\n",
    "https://github.com/Kaosui/-GCN/blob/main/nn/GAT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9485],\n",
       "        [-0.6959],\n",
       "        [-0.5467]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GATConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels,add_loop=True,heads=1):\n",
    "        super().__init__(aggr='add',flow='source_to_target',node_dim =-2)#聚合的维度  \n",
    "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "x = torch.rand([3,2])\n",
    "edge_index = torch.tensor( [[0,1],\n",
    "                            [1,2]])\n",
    "model=GCNConv(x.shape[-1],1)\n",
    "model(x,edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pyg2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce796860ea43bd64a88659bd336c1722a32ada0c5256b44271be361e52750df2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
